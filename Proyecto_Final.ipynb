{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORscEtqyrGax"
      },
      "source": [
        "# Poyecto Final IA, CLASIFICADOR DE ESTRELLAS\n",
        "#Geuseppe Segrera\n",
        "###Introducción\n",
        "El presente proyecto corresponde a un clasificador de estrellas, en el cual se utilizaran 6 caracteristicas para clasificarlas:\n",
        "* Clase espectral\n",
        "* Color\n",
        "* Temperatura\n",
        "* Radio relativo\n",
        "* Luminosidad relativa\n",
        "* Magnitud absoluta\n",
        "\n",
        "Junto con estas caracteristicas se pretende poder clasificar cada estrella de entre los 6 tipos que se tienen, los cuales son:\n",
        "* Enana Roja (0)\n",
        "* Enana Marron (1)\n",
        "* Enana blanca (2)\n",
        "* Secuencia principal (3)\n",
        "* Super Gigante(4)\n",
        "* Hiper Gigante (5)\n",
        "\n",
        "Los metodos escogidos para realizar los casificadores son las maquinas de soporte vectorial y las redes neuronales artificiales.\n",
        "\n",
        "Enlace del dataset: https://www.kaggle.com/brsdincer/star-type-classification/version/1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS7XcaR21qdv"
      },
      "source": [
        "###Desarrollo del proyecto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiWQuacKBFH-"
      },
      "source": [
        "#Se importan las librerias a usar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import decomposition\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as kr\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6suzoePLUTTr"
      },
      "source": [
        "* Lectura y depuración de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCMXv3CFeAAO",
        "outputId": "6640a0c4-7e79-4f99-9839-6698a1265b0d"
      },
      "source": [
        "#Se leen los datos\n",
        "dataframe = pd.read_csv(\"Stars.csv\",sep=';')\n",
        "\n",
        "#Se observan los 10 primeros para saber como son\n",
        "ten_samples=dataframe.head(10)\n",
        "print(ten_samples)\n",
        "\n",
        "#Contamos cuantas muestras hay en total\n",
        "dataframe.count(axis=0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Temperature         L       R    A_M Color Spectral_Class  Type\n",
            "0         3068  0.002400  0.1700  16.12   Red              M     0\n",
            "1         3042  0.000500  0.1542  16.60   Red              M     0\n",
            "2         2600  0.000300  0.1020  18.70   Red              M     0\n",
            "3         2800  0.000200  0.1600  16.65   Red              M     0\n",
            "4         1939  0.000138  0.1030  20.06   Red              M     0\n",
            "5         2840  0.000650  0.1100  16.98   Red              M     0\n",
            "6         2637  0.000730  0.1270  17.22   Red              M     0\n",
            "7         2600  0.000400  0.0960  17.40   Red              M     0\n",
            "8         2650  0.000690  0.1100  17.45   Red              M     0\n",
            "9         2700  0.000180  0.1300  16.05   Red              M     0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Temperature       240\n",
              "L                 240\n",
              "R                 240\n",
              "A_M               240\n",
              "Color             240\n",
              "Spectral_Class    240\n",
              "Type              240\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIlBx1lN2Ihq",
        "outputId": "4ca17dab-7759-4cc0-89b8-a252b75d7906"
      },
      "source": [
        "#Visualizamos las caracteristicas cualitativas\n",
        "print(dataframe.groupby('Spectral_Class').size())\n",
        "print(dataframe.groupby('Color').size())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectral_Class\n",
            "A     19\n",
            "B     46\n",
            "F     17\n",
            "G      1\n",
            "K      6\n",
            "M    111\n",
            "O     40\n",
            "dtype: int64\n",
            "Color\n",
            "Blue                   56\n",
            "Blue White             10\n",
            "Blue white              4\n",
            "Blue-White              1\n",
            "Blue-white             26\n",
            "Orange                  2\n",
            "Orange-Red              1\n",
            "Pale yellow orange      1\n",
            "Red                   112\n",
            "White                   7\n",
            "White-Yellow            1\n",
            "Whitish                 2\n",
            "Yellowish               1\n",
            "Yellowish White         3\n",
            "white                   3\n",
            "yellow-white            8\n",
            "yellowish               2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZT6Ztbh15ab",
        "outputId": "d1773bac-40c9-48c2-d0bc-c505c8c4391e"
      },
      "source": [
        "#Reemplazamos las cadenas de caracteres por datos cuantitativos\n",
        "dataframe = dataframe.replace([ 'A', 'B', 'F', 'G', 'K', 'M', 'O'], [ 0, 1, 2, 3, 4, 5, 6])\n",
        "dataframe = dataframe.replace(['Blue','Red'], [0,1])\n",
        "dataframe = dataframe.replace([ 'Blue White', 'Blue white', 'Blue-White', 'Blue-white'], 2)\n",
        "dataframe = dataframe.replace([ 'Orange', 'Orange-Red', 'Pale yellow orange'], 3)\n",
        "dataframe = dataframe.replace([ 'White', 'Whitish', 'white'], 4)\n",
        "dataframe = dataframe.replace([ 'White-Yellow', 'Yellowish White', 'yellow-white'], 5)\n",
        "dataframe = dataframe.replace([ 'Yellowish', 'yellowish'], 6)\n",
        "\n",
        "#Confirmamos el reemplazo\n",
        "print(dataframe.groupby('Color').size())\n",
        "print(dataframe.groupby('Spectral_Class').size())\n",
        "\n",
        "#Creamos un nuevo archivo csv con los datos limpios\n",
        "dataframe.to_csv('Stars_clean.csv')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color\n",
            "0     56\n",
            "1    112\n",
            "2     41\n",
            "3      4\n",
            "4     12\n",
            "5     12\n",
            "6      3\n",
            "dtype: int64\n",
            "Spectral_Class\n",
            "0     19\n",
            "1     46\n",
            "2     17\n",
            "3      1\n",
            "4      6\n",
            "5    111\n",
            "6     40\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xemr2hwSU739"
      },
      "source": [
        "* Extracción caracteristicas y etiquetas, escalización, división entre train y test, y verificación de uso PCA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUKPvpmxCcA-",
        "outputId": "b749e274-b88b-4465-9e55-9964f6d87912"
      },
      "source": [
        "#Extraemos las caractersiticas del dataset\n",
        "features = dataframe[['Temperature', 'L', 'R', 'A_M','Color','Spectral_Class']].values\n",
        "#Extraemos las etiquetas\n",
        "labels = dataframe['Type'].values\n",
        "\n",
        "#Escalizamos las caracteristicas\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(features)# el fit de los datos\n",
        "features = scaler.transform(features)\n",
        "\n",
        "#Se verifica si es prudente realizar PCA\n",
        "pca = decomposition.PCA(n_components=5,whiten=True,svd_solver='arpack')\n",
        "pca.fit(features)\n",
        "features = pca.transform(features)\n",
        "var_expl=pca.explained_variance_ratio_\n",
        "print(\"Pesos de PCA:\",var_expl)\n",
        "add=var_expl[0]+var_expl[1]+var_expl[2]+var_expl[3]+var_expl[4]\n",
        "print(\"Varianza explicada porlas cinco primeras componenetes:\",add)\n",
        "\n",
        "#Dividimos en conjunto de test y train con un 75% para el conjunto de train y 25% para test\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, random_state=0,train_size=0.75)\n",
        "\n",
        "#Mostramos la cantidad de muestras para el conjunto de train y test\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos de PCA: [0.4259625  0.24111583 0.17319635 0.07517904 0.04529431]\n",
            "Varianza explicada porlas cinco primeras componenetes: 0.9607480380883548\n",
            "(180, 5)\n",
            "(60, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nXKgxuQVJQl"
      },
      "source": [
        "* Se busca el mejor clasificador utilizando Maquinas de soporte vectorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgt13X-AMJRm"
      },
      "source": [
        "#Se crean las listas para guardar lo hiperparámetros a iterar\n",
        "kernels=['linear', 'poly', 'rbf', 'sigmoid']\n",
        "decision=['ovo','ovr']\n",
        "lista_hiper_param_MSV=[]\n",
        "lista_metrics_MSV=[]\n",
        "lista_metrics_mean_MSV=[]\n",
        "#Se iteran los hiperparámetros\n",
        "for iter_C in np.arange(1,6,0.1):#Se itera el coeficiente regularización\n",
        "  for iter_shape in np.arange(0,1,1):#Se itera la desición multiclase\n",
        "    for iter_kernel in np.arange(0,3,1):#Se itera el tipo de kernel\n",
        "      #Se configura el método\n",
        "      msv = svm.SVC(kernel=kernels[iter_kernel],C=(0.001*(10**iter_C)),decision_function_shape=decision[iter_shape],probability=True)\n",
        "      \n",
        "      #Se ajusta el método a los datos\n",
        "      msv.fit(X_train, y_train)\n",
        "\n",
        "      #Se predicen las etiquetas y sus probabilidades para el conjunto de entrenamiento\n",
        "      y_train_predicted_MSV=msv.predict(X_train)\n",
        "      y_train_scores_MSV=msv.predict_proba(X_train)\n",
        "\n",
        "      #Se obtienen los valores de las metricas para el conjunto de entrenamiento\n",
        "      MCC_MSV_train = matthews_corrcoef(y_train, y_train_predicted_MSV)\n",
        "      F1_MSV_train = f1_score(y_train, y_train_predicted_MSV,average='macro')\n",
        "      roc_auc_MSV_train=roc_auc_score(y_train, y_train_scores_MSV,multi_class=decision[iter_shape])\n",
        "\n",
        "      #Se predicen las etiquetas y sus probabilidades para el conjunto de validación\n",
        "      y_test_predicted_MSV=msv.predict(X_test)\n",
        "      y_test_scores_MSV=msv.predict_proba(X_test)\n",
        "\n",
        "      #Se obtienen los valores de las metricas para el conjunto de validación\n",
        "      MCC_MSV_test = matthews_corrcoef(y_test, y_test_predicted_MSV)\n",
        "      F1_MSV_test = f1_score(y_test, y_test_predicted_MSV,average='macro')\n",
        "      roc_auc_MSV_test=roc_auc_score(y_test, y_test_scores_MSV,multi_class=decision[iter_shape])\n",
        "\n",
        "      #Se guardan los valores de hiperparametros y metricas, tanto en el conjunto de train como en el de test, para cada iteración\n",
        "      hiper_param_MSV=(iter_C,iter_shape,iter_kernel)\n",
        "      metrics_MSV=(MCC_MSV_train, F1_MSV_train,roc_auc_MSV_train,MCC_MSV_test, F1_MSV_test,roc_auc_MSV_test)\n",
        "      lista_metrics_mean_MSV.append(np.mean(metrics_MSV))\n",
        "      lista_metrics_MSV.append(metrics_MSV)\n",
        "      lista_hiper_param_MSV.append(hiper_param_MSV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQn98fUnjwBN"
      },
      "source": [
        "* Se encuentran los hiperparametros correspondientes al mejor clasificador por medio de maquinas de soporte vectorial "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbgpcY3n0Ghm",
        "outputId": "de64b26a-3258-4c9e-a391-07f12975aa3e"
      },
      "source": [
        "#Se imprimen los hiperparámetros para los cuales el promedio de las métricas fué el mayor\n",
        "best_hiper_param_MSV=lista_hiper_param_MSV[np.argmax(lista_metrics_mean_MSV)]\n",
        "print(best_hiper_param_MSV)\n",
        "#Se imprime el promedio más alto de las métricas\n",
        "print(lista_metrics_mean_MSV[np.argmax(lista_metrics_mean_MSV)])\n",
        "#Se imprimen los valores de cada métrica para las cuales dió el promedio mas alto\n",
        "print(lista_metrics_MSV[np.argmax(lista_metrics_mean_MSV)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3.500000000000002, 0, 0)\n",
            "1.0\n",
            "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob4yVFTRkKtw"
      },
      "source": [
        "* Se comprueba el funcionamiento del clasificador usando los hiperparámetros encontrados anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06UhL0-i5iDs",
        "outputId": "1ecd20a8-902e-4be8-bfbe-e8625a21079e"
      },
      "source": [
        "#Se configura el clasificador\n",
        "msv = svm.SVC(kernel=kernels[best_hiper_param_MSV[2]],C=(0.001*(10**best_hiper_param_MSV[0])),decision_function_shape=decision[best_hiper_param_MSV[1]],probability=True)\n",
        "\n",
        "#Se ajusta el método a los datos\n",
        "msv.fit(X_train, y_train)\n",
        "\n",
        "#Se predicen las etiquetas y sus probabilidades para el conjunto de entrenamiento\n",
        "y_train_predicted_MSV=msv.predict(X_train)\n",
        "y_train_scores_MSV=msv.predict_proba(X_train)\n",
        "\n",
        "#Se obtienen las métricas para el conjunto de entrenamiento\n",
        "MCC_MSV_train = matthews_corrcoef(y_train, y_train_predicted_MSV)\n",
        "F1_MSV_train = f1_score(y_train, y_train_predicted_MSV,average='macro')\n",
        "roc_auc_MSV_train=roc_auc_score(y_train, y_train_scores_MSV,multi_class=decision[best_hiper_param_MSV[1]])\n",
        "\n",
        "#Se predicen las etiquetas y sus probabilidades para el conjunto de validación\n",
        "y_test_predicted_MSV=msv.predict(X_test)\n",
        "y_test_scores_MSV=msv.predict_proba(X_test)\n",
        "\n",
        "#Se obtienen las métricas para el conjunto de validación\n",
        "MCC_MSV_test = matthews_corrcoef(y_test, y_test_predicted_MSV)\n",
        "F1_MSV_test = f1_score(y_test, y_test_predicted_MSV,average='macro')\n",
        "roc_auc_MSV_test=roc_auc_score(y_test, y_test_scores_MSV,multi_class=decision[0])\n",
        "\n",
        "#Se imprimen las métricas\n",
        "print(\"MCC_MSV_train:\",MCC_MSV_train)\n",
        "print(\"F1_MSV_train:\",F1_MSV_train)\n",
        "print(\"AUC_MSV_train:\",roc_auc_MSV_train)\n",
        "print(\"MCC_MSV_test:\",MCC_MSV_test)\n",
        "print(\"F1_MSV_test:\",F1_MSV_test)\n",
        "print(\"AUC_MSV_test:\",roc_auc_MSV_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC_MSV_train: 1.0\n",
            "F1_MSV_train: 1.0\n",
            "AUC_MSV_train: 1.0\n",
            "MCC_MSV_test: 1.0\n",
            "F1_MSV_test: 1.0\n",
            "AUC_MSV_test: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxFQzc9RmVbW"
      },
      "source": [
        "* Se busca el mejor clasificador utilizando redes neuronales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8AIwT8E5IwB"
      },
      "source": [
        "#Se crean las listas para guardar lo hiperparametros a iterar\n",
        "funtion=['identity', 'logistic', 'tanh', 'relu']\n",
        "lista_hiper_param_ANN=[]\n",
        "lista_metrics_ANN=[]\n",
        "lista_metrics_mean_ANN=[]\n",
        "#Se iteran los hiperparametros\n",
        "for iter_h_layers in np.arange(1,20,1):#Se itera el la cantidad de capas ocultas\n",
        "  for iter_neurons in np.arange(1,20,1):#Se itera la cantidad de neuronas\n",
        "    for iter_funtion in np.arange(0,3,1):#Se itera las función de decisión\n",
        "\n",
        "      #Configuramos el método\n",
        "      ANN = MLPClassifier(hidden_layer_sizes=(iter_h_layers, iter_neurons),activation=funtion[iter_funtion],random_state=1, max_iter=500,verbose=False,learning_rate='adaptive', learning_rate_init=0.01)\n",
        "      \n",
        "      #Entrenamos el método\n",
        "      ANN.fit(X_train, y_train)\n",
        "\n",
        "      #Se predicen las etiquetas y sus probabilidades para el conjunto de entrenamiento\n",
        "      y_train_predicted_ANN=ANN.predict(X_train)\n",
        "      y_train_scores_ANN=ANN.predict_proba(X_train)\n",
        "\n",
        "      #Se obtienen las metricas para el conjunto de entrenamiento\n",
        "      MCC_ANN_train = matthews_corrcoef(y_train, y_train_predicted_ANN)\n",
        "      F1_ANN_train = f1_score(y_train, y_train_predicted_ANN,average='macro')\n",
        "      roc_auc_ANN_train = roc_auc_score(y_train, y_train_scores_ANN,multi_class='ovo')\n",
        "\n",
        "      #Se predicen las etiquetas y sus probabilidades para el conjunto de validación\n",
        "      y_test_predicted_ANN=ANN.predict(X_test)\n",
        "      y_test_scores_ANN=ANN.predict_proba(X_test)\n",
        "\n",
        "      #Se obtienen las metricas para el conjunto de validación\n",
        "      MCC_ANN_test = matthews_corrcoef(y_test, y_test_predicted_ANN)\n",
        "      F1_ANN_test = f1_score(y_test, y_test_predicted_ANN,average='macro')\n",
        "      roc_auc_ANN_test = roc_auc_score(y_test, y_test_scores_ANN,multi_class='ovo')\n",
        "\n",
        "      #Se guardan los valores de hiperparametros y metricas, tanto en el conjunto de train como en el de test, para cada iteración\n",
        "      hiper_param_ANN=(iter_h_layers,iter_neurons,iter_funtion)\n",
        "      metrics_ANN=(MCC_ANN_train, F1_ANN_train,roc_auc_ANN_train,MCC_ANN_test, F1_ANN_test,roc_auc_ANN_test)\n",
        "      lista_metrics_mean_ANN.append(np.mean(metrics_ANN))\n",
        "      lista_metrics_ANN.append(metrics_ANN)\n",
        "      lista_hiper_param_ANN.append(hiper_param_ANN)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8TZGpO0mZ3V"
      },
      "source": [
        "* Se encuentran los hiperparametros correspondientes al mejor clasificador por medio de redes neuronales "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0OrVAoUImV_",
        "outputId": "c696e64a-8c82-41f2-c151-8d9b47ae07b8"
      },
      "source": [
        "#Se imprimen los hiperparámetros para los cuales el promedio de las métricas fué el mayor\n",
        "best_hiper_param_ANN=lista_hiper_param_ANN[np.argmax(lista_metrics_mean_ANN)]\n",
        "print(best_hiper_param_ANN)\n",
        "#Se imprime el promedio más alto de las métricas\n",
        "print(lista_metrics_mean_ANN[np.argmax(lista_metrics_mean_ANN)])\n",
        "#Se imprimen los valores de cada métrica para las cuales dió el promedio mas alto\n",
        "print(lista_metrics_ANN[np.argmax(lista_metrics_mean_ANN)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 8, 0)\n",
            "1.0\n",
            "(1.0, 1.0, 1.0, 1.0, 1.0, 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyyB9dzcmbGL"
      },
      "source": [
        "* Se comprueba el funcionamiento del clasificador usando los hiperparámetros encontrados anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKlc9T5IIy-o",
        "outputId": "c117ae0d-2cd5-48b8-8f32-4c4cbd66700f"
      },
      "source": [
        "#Configuramos el método\n",
        "ANN = MLPClassifier(hidden_layer_sizes=(best_hiper_param_ANN[0], best_hiper_param_ANN[1]),activation=funtion[best_hiper_param_ANN[2]],random_state=1, max_iter=500,verbose=False,learning_rate='adaptive', learning_rate_init=0.01)\n",
        "\n",
        "#Entrenamos el método\n",
        "ANN.fit(X_train, y_train)\n",
        "\n",
        "#Se predicen las etiquetas y sus probabilidades para el conjunto de entrenamiento\n",
        "y_train_predicted_ANN=ANN.predict(X_train)\n",
        "y_train_scores_ANN=ANN.predict_proba(X_train)\n",
        "\n",
        "#Se obtienen las métricas para el conjunto de entrenamiento\n",
        "MCC_ANN_train = matthews_corrcoef(y_train, y_train_predicted_ANN)\n",
        "F1_ANN_train = f1_score(y_train, y_train_predicted_ANN,average='macro')\n",
        "roc_auc_ANN_train = roc_auc_score(y_train, y_train_scores_ANN,multi_class='ovo')\n",
        "\n",
        "#Se predicen las etiquetas y sus probabilidades para el conjunto de validación\n",
        "y_test_predicted_ANN=ANN.predict(X_test)\n",
        "y_test_scores_ANN=ANN.predict_proba(X_test)\n",
        "\n",
        "#Se obtienen las métricas para el conjunto de validación\n",
        "MCC_ANN_test = matthews_corrcoef(y_test, y_test_predicted_ANN)\n",
        "F1_ANN_test = f1_score(y_test, y_test_predicted_ANN,average='macro')\n",
        "roc_auc_ANN_test = roc_auc_score(y_test, y_test_scores_ANN,multi_class='ovo')\n",
        "\n",
        "#Se imprimen las métricas\n",
        "print(\"MCC_ANN_train:\",MCC_ANN_train)\n",
        "print(\"F1_ANN_train:\",F1_ANN_train)\n",
        "print(\"AUC_ANN_train:\",roc_auc_ANN_train)\n",
        "print(\"MCC_ANN_test:\",MCC_ANN_test)\n",
        "print(\"F1_ANN_test:\",F1_ANN_test)\n",
        "print(\"AUC_ANN_test:\",roc_auc_ANN_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCC_ANN_train: 1.0\n",
            "F1_ANN_train: 1.0\n",
            "AUC_ANN_train: 1.0\n",
            "MCC_ANN_test: 1.0\n",
            "F1_ANN_test: 1.0\n",
            "AUC_ANN_test: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsyWjzAcklXA"
      },
      "source": [
        "###Conclusiones\n",
        "* Se encontró que ambos métodos producen clasificadores con una puntuación excelente en las métricas utilizadas, la selección entre estos recaería entonces en la velocidad y consumo de recursos de cada uno.\n",
        "* Se encontró por medio de una busqueda por fuerza bruta los mejores hiperparámetros para cada método, estos dieron las metricas tanto en el conjunto de validación como en el de entrenamiento todas con un valor de 1 lo que quiere decir que se clasifican correctamente todas las muestras.\n",
        "* No se hizo uso de PCA ya que las 5 primeras componentes principales de los datos no explican la varianza lo suficiente, dando un valor de 96.07% lo que no llega al valor esperado que es de por lo menos mayor al 97%. Por esto no se llegaba a un beneficio utilizando PCA.\n",
        "* Se encontró que los métodos lineales separaban de una manera excelente los datos, ya que al hacer la iteración de hiperparámetros estos dieron las mejores métricas.\n",
        "* Para decidir cual era el mejor conjunto de datos se tomo en cuenta las métricas evaluadas para el conjunto de entrenamiento y el de evaluación para así no sobre ajustar el método a ninguno de los dos conjuntos y encontrar realmente cual producia mejores resultados, esto se hizo almacenando el promedio de todas estas métricas y encontrando su valor máximo de entre todas las iteraciones hechas.\n"
      ]
    }
  ]
}